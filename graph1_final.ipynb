{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from datetime import datetime, timedelta\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# some global constants\n",
    "_FORMAT_TIME = '%H:%M'\n",
    "_LARGEST_DELAY = 15 # in minutes, largest delay of vehicles considered at each station\n",
    "_DEFAULT_YEAR_ = 2018\n",
    "_MAX_STATIONS_ = 8\n",
    "_MIN_PROB_THRES_  = 0.5\n",
    "_WALKING_VELOCITY = 1.0\n",
    "_WALKING_VARIANCE = 0.2\n",
    "_RELAXATION_FACTOR= -20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will focus on all the stops within 10km of the Zurich train station.\n",
    "\n",
    "We calculated distance using this formula:\n",
    "\n",
    "$$ DISTANCE = 2* arcsin\\sqrt{sin^2\\frac{a}{2}+cos(Lat1)*cos(Lat2)*sin^2\\frac{b}{2}} * Earth Radius $$\n",
    "$$ a = Lat1-Lat2, b = Lon1 - Lon2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo = pd.read_csv('./data/BFKOORD_GEO', sep=\"%\", header=None,error_bad_lines=False)\n",
    "geo.columns = ['data','name']\n",
    "geo.name = geo.name.apply(str.lstrip).apply(str.rstrip)\n",
    "\n",
    "geo[['station_number','longtitude','latitude','height']] = geo.data.str.split(expand=True)#.apply(float)\n",
    "geo.drop('data',axis=1,inplace=True)\n",
    "\n",
    "# station in Zurich\n",
    "zurich = geo[geo.station_number==\"8503000\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>station_number</th>\n",
       "      <th>longtitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zürich HB</td>\n",
       "      <td>8503000</td>\n",
       "      <td>8.540192</td>\n",
       "      <td>47.378177</td>\n",
       "      <td>408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name station_number longtitude   latitude height\n",
       "0  Zürich HB        8503000   8.540192  47.378177    408"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zurich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute the distance with the longtitude and the latitude\n",
    "from math import sin, cos, sqrt, atan2, radians,asin\n",
    "def compute_distance(point_1_lat, point_1_lon, point_2_lat=zurich.latitude, point_2_lon=zurich.longtitude):\n",
    "    # approximate radius of earth in km\n",
    "    R = 6378.137 # earth radius\n",
    "\n",
    "    lat1 = radians(float(point_1_lat))\n",
    "    lon1 = radians(float(point_1_lon))\n",
    "    lat2 = radians(float(point_2_lat))\n",
    "    lon2 = radians(float(point_2_lon))\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * asin(sqrt(a))\n",
    "\n",
    "    distance = R * c\n",
    "    return np.round(distance,3) # return distance in kilometres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "distance = []\n",
    "for log,lat in zip(geo.longtitude,geo.latitude):\n",
    "    distance.append(compute_distance(lat,log))\n",
    "\n",
    "## find the stations lie inside the radius of 10km\n",
    "geo['distance'] = distance\n",
    "zurich_neigh_station = geo[geo.distance <= 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Process the dataframe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build seperate graphs for weekday, weekend and National Holiday, because different schedules are applied to them. In this project, we choose 28.04.2018, 29.04.2018, 30.04.2018 to build our graph, which can be changed in the argument \"date\".\n",
    "\n",
    "Note that we assume the schedule for weekday (weekend, National Holiday) does not change throughout the year. so we can pick one day to construct the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '30.04.2018'\n",
    "df = pd.read_csv(\"./data/grouped_201804.csv\")\n",
    "df_day = df[(df['date_of_trip'] == date)&(df['additional_trip'] == False)&(df['not_stop'] == False)]\n",
    "df_day = df_day.reset_index(drop=True)\n",
    "nan = np.nan\n",
    "df_day['Timetable'] = df_day.Timetable.map(lambda x:eval(x))\n",
    "df_day = df_day[['date_of_trip', 'identifies_of_trip', 'Timetable', 'train_number']]\n",
    "all_station = []\n",
    "for idx, row in df_day.iterrows():\n",
    "    station = []\n",
    "    for i in range(len(row['Timetable'])):\n",
    "        station.append(row['Timetable'][i][0])\n",
    "    all_station.append(station)\n",
    "df_day['station_name'] = all_station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_of_trip</th>\n",
       "      <th>identifies_of_trip</th>\n",
       "      <th>Timetable</th>\n",
       "      <th>train_number</th>\n",
       "      <th>station_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.04.2018</td>\n",
       "      <td>85:11:1507:002</td>\n",
       "      <td>[[Zürich HB, 23400, 23593, 23940, 23984], [Zür...</td>\n",
       "      <td>1507</td>\n",
       "      <td>[Zürich HB, Zürich Flughafen]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.04.2018</td>\n",
       "      <td>85:11:1509:003</td>\n",
       "      <td>[[Zürich HB, 27000, 27113, 27540, 27582], [Zür...</td>\n",
       "      <td>1509</td>\n",
       "      <td>[Zürich HB, Zürich Flughafen]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.04.2018</td>\n",
       "      <td>85:11:1510:003</td>\n",
       "      <td>[[Zürich Flughafen, 25860, 25906, 25980, 26102...</td>\n",
       "      <td>1510</td>\n",
       "      <td>[Zürich Flughafen, Zürich HB]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.04.2018</td>\n",
       "      <td>85:11:1511:003</td>\n",
       "      <td>[[Zürich HB, 30600, 30690, 31140, 31223], [Zür...</td>\n",
       "      <td>1511</td>\n",
       "      <td>[Zürich HB, Zürich Flughafen]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.04.2018</td>\n",
       "      <td>85:11:1512:003</td>\n",
       "      <td>[[Zürich Flughafen, 29460, 29451, 29580, 29710...</td>\n",
       "      <td>1512</td>\n",
       "      <td>[Zürich Flughafen, Zürich HB]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30.04.2018</td>\n",
       "      <td>85:11:1513:003</td>\n",
       "      <td>[[Zürich HB, 34200, 34329, 34740, 34776], [Zür...</td>\n",
       "      <td>1513</td>\n",
       "      <td>[Zürich HB, Zürich Flughafen]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30.04.2018</td>\n",
       "      <td>85:11:1514:003</td>\n",
       "      <td>[[Zürich Flughafen, 33060, 33121, 33180, 33300...</td>\n",
       "      <td>1514</td>\n",
       "      <td>[Zürich Flughafen, Zürich HB]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30.04.2018</td>\n",
       "      <td>85:11:1515:003</td>\n",
       "      <td>[[Zürich HB, 37800, 37948, 38340, 38411], [Zür...</td>\n",
       "      <td>1515</td>\n",
       "      <td>[Zürich HB, Zürich Flughafen]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30.04.2018</td>\n",
       "      <td>85:11:1516:001</td>\n",
       "      <td>[[Zürich Flughafen, 36660, 36612, 36780, 36838...</td>\n",
       "      <td>1516</td>\n",
       "      <td>[Zürich Flughafen, Zürich HB]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>30.04.2018</td>\n",
       "      <td>85:11:1517:001</td>\n",
       "      <td>[[Zürich HB, 41400, 41402, 41940, 41988], [Zür...</td>\n",
       "      <td>1517</td>\n",
       "      <td>[Zürich HB, Zürich Flughafen]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  date_of_trip identifies_of_trip  \\\n",
       "0   30.04.2018     85:11:1507:002   \n",
       "1   30.04.2018     85:11:1509:003   \n",
       "2   30.04.2018     85:11:1510:003   \n",
       "3   30.04.2018     85:11:1511:003   \n",
       "4   30.04.2018     85:11:1512:003   \n",
       "5   30.04.2018     85:11:1513:003   \n",
       "6   30.04.2018     85:11:1514:003   \n",
       "7   30.04.2018     85:11:1515:003   \n",
       "8   30.04.2018     85:11:1516:001   \n",
       "9   30.04.2018     85:11:1517:001   \n",
       "\n",
       "                                           Timetable train_number  \\\n",
       "0  [[Zürich HB, 23400, 23593, 23940, 23984], [Zür...         1507   \n",
       "1  [[Zürich HB, 27000, 27113, 27540, 27582], [Zür...         1509   \n",
       "2  [[Zürich Flughafen, 25860, 25906, 25980, 26102...         1510   \n",
       "3  [[Zürich HB, 30600, 30690, 31140, 31223], [Zür...         1511   \n",
       "4  [[Zürich Flughafen, 29460, 29451, 29580, 29710...         1512   \n",
       "5  [[Zürich HB, 34200, 34329, 34740, 34776], [Zür...         1513   \n",
       "6  [[Zürich Flughafen, 33060, 33121, 33180, 33300...         1514   \n",
       "7  [[Zürich HB, 37800, 37948, 38340, 38411], [Zür...         1515   \n",
       "8  [[Zürich Flughafen, 36660, 36612, 36780, 36838...         1516   \n",
       "9  [[Zürich HB, 41400, 41402, 41940, 41988], [Zür...         1517   \n",
       "\n",
       "                    station_name  \n",
       "0  [Zürich HB, Zürich Flughafen]  \n",
       "1  [Zürich HB, Zürich Flughafen]  \n",
       "2  [Zürich Flughafen, Zürich HB]  \n",
       "3  [Zürich HB, Zürich Flughafen]  \n",
       "4  [Zürich Flughafen, Zürich HB]  \n",
       "5  [Zürich HB, Zürich Flughafen]  \n",
       "6  [Zürich Flughafen, Zürich HB]  \n",
       "7  [Zürich HB, Zürich Flughafen]  \n",
       "8  [Zürich Flughafen, Zürich HB]  \n",
       "9  [Zürich HB, Zürich Flughafen]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_day.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate lineid-tripid dictionary.\n",
    "lineid_trip = df_day[[\"train_number\", \"identifies_of_trip\"]] \\\n",
    "            .groupby([\"train_number\"])[\"identifies_of_trip\"] \\\n",
    "            .apply(lambda x: \"%s\" % ','.join(x))\n",
    "lineid_trip = lineid_trip.to_frame().reset_index()\n",
    "lineid_trip['identifies_of_trip'] = lineid_trip['identifies_of_trip'].map(lambda x: list(set(x.split(','))))\n",
    "lineid_trip_dict = dict(zip(lineid_trip.train_number, lineid_trip.identifies_of_trip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate tripid-station dictionary\n",
    "trip_id_dict = dict()\n",
    "for _, row in df_day.iterrows():\n",
    "    trip_id = row['identifies_of_trip']\n",
    "    one_trip = dict()\n",
    "    for item in row['Timetable']:\n",
    "        arr_time = item[1]\n",
    "        arr_time = '{}:{}'.format(arr_time//3600, (arr_time%3600)//60)\n",
    "        dep_time = item[3]\n",
    "        dep_time = '{}:{}'.format(dep_time//3600, (dep_time%3600)//60)\n",
    "        one_trip[item[0]] = [arr_time, dep_time]\n",
    "    trip_id_dict[trip_id] = one_trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"./data/timetable180430_test.pickle\", 'wb') as handle:\n",
    "    pickle.dump(trip_id_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"./data/lineid_trip180430_test.pickle\", 'wb') as handle:\n",
    "    pickle.dump(lineid_trip_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Add neighbor station "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also add \"Walking\" as one specific transportation type in the graph. Here, we calculate the minimum/maximum latitude/longtitude range of a fixed station within a fixed distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>station_number</th>\n",
       "      <th>longtitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>height</th>\n",
       "      <th>distance</th>\n",
       "      <th>neighbor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zimmerberg-Basistunnel</td>\n",
       "      <td>0000176</td>\n",
       "      <td>8.521961</td>\n",
       "      <td>47.351679</td>\n",
       "      <td>0</td>\n",
       "      <td>3.254</td>\n",
       "      <td>[Zimmerberg-Basistunnel]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Urdorf</td>\n",
       "      <td>8502220</td>\n",
       "      <td>8.434713</td>\n",
       "      <td>47.390882</td>\n",
       "      <td>442</td>\n",
       "      <td>8.075</td>\n",
       "      <td>[Urdorf, Urdorf, Bahnhof]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Birmensdorf ZH</td>\n",
       "      <td>8502221</td>\n",
       "      <td>8.437543</td>\n",
       "      <td>47.357432</td>\n",
       "      <td>488</td>\n",
       "      <td>8.076</td>\n",
       "      <td>[Birmensdorf ZH, Birmensdorf ZH, Bahnhof, Birm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bonstetten-Wettswil</td>\n",
       "      <td>8502222</td>\n",
       "      <td>8.468175</td>\n",
       "      <td>47.325896</td>\n",
       "      <td>528</td>\n",
       "      <td>7.961</td>\n",
       "      <td>[Bonstetten-Wettswil, Bonstetten-Wettswil, Bah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Urdorf Weihermatt</td>\n",
       "      <td>8502229</td>\n",
       "      <td>8.430330</td>\n",
       "      <td>47.380971</td>\n",
       "      <td>456</td>\n",
       "      <td>8.287</td>\n",
       "      <td>[Urdorf Weihermatt, Urdorf Weihermatt, Bahnhof]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Waldegg, Birmensdorferstrasse</td>\n",
       "      <td>8502559</td>\n",
       "      <td>8.463472</td>\n",
       "      <td>47.368305</td>\n",
       "      <td>588</td>\n",
       "      <td>5.887</td>\n",
       "      <td>[Waldegg, Birmensdorferstrasse, Waldegg, Post]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Zürich, Goldbrunnenplatz</td>\n",
       "      <td>8502572</td>\n",
       "      <td>8.513918</td>\n",
       "      <td>47.370293</td>\n",
       "      <td>421</td>\n",
       "      <td>2.166</td>\n",
       "      <td>[Zürich, Goldbrunnenplatz, Zürich, Zwinglihaus]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Aesch ZH, Gemeindehaus</td>\n",
       "      <td>8502876</td>\n",
       "      <td>8.438705</td>\n",
       "      <td>47.338209</td>\n",
       "      <td>537</td>\n",
       "      <td>8.852</td>\n",
       "      <td>[Aesch ZH, Gemeindehaus]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bonstetten, Dorfplatz</td>\n",
       "      <td>8502885</td>\n",
       "      <td>8.467781</td>\n",
       "      <td>47.315088</td>\n",
       "      <td>528</td>\n",
       "      <td>8.897</td>\n",
       "      <td>[Bonstetten, Dorfplatz]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Birmensdorf ZH, Zentrum</td>\n",
       "      <td>8502950</td>\n",
       "      <td>8.437173</td>\n",
       "      <td>47.353936</td>\n",
       "      <td>468</td>\n",
       "      <td>8.223</td>\n",
       "      <td>[Birmensdorf ZH, Zentrum]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name station_number  longtitude   latitude height  \\\n",
       "0         Zimmerberg-Basistunnel        0000176    8.521961  47.351679      0   \n",
       "1                         Urdorf        8502220    8.434713  47.390882    442   \n",
       "2                 Birmensdorf ZH        8502221    8.437543  47.357432    488   \n",
       "3            Bonstetten-Wettswil        8502222    8.468175  47.325896    528   \n",
       "4              Urdorf Weihermatt        8502229    8.430330  47.380971    456   \n",
       "5  Waldegg, Birmensdorferstrasse        8502559    8.463472  47.368305    588   \n",
       "6       Zürich, Goldbrunnenplatz        8502572    8.513918  47.370293    421   \n",
       "7         Aesch ZH, Gemeindehaus        8502876    8.438705  47.338209    537   \n",
       "8          Bonstetten, Dorfplatz        8502885    8.467781  47.315088    528   \n",
       "9        Birmensdorf ZH, Zentrum        8502950    8.437173  47.353936    468   \n",
       "\n",
       "   distance                                           neighbor  \n",
       "0     3.254                           [Zimmerberg-Basistunnel]  \n",
       "1     8.075                          [Urdorf, Urdorf, Bahnhof]  \n",
       "2     8.076  [Birmensdorf ZH, Birmensdorf ZH, Bahnhof, Birm...  \n",
       "3     7.961  [Bonstetten-Wettswil, Bonstetten-Wettswil, Bah...  \n",
       "4     8.287    [Urdorf Weihermatt, Urdorf Weihermatt, Bahnhof]  \n",
       "5     5.887     [Waldegg, Birmensdorferstrasse, Waldegg, Post]  \n",
       "6     2.166    [Zürich, Goldbrunnenplatz, Zürich, Zwinglihaus]  \n",
       "7     8.852                           [Aesch ZH, Gemeindehaus]  \n",
       "8     8.897                            [Bonstetten, Dorfplatz]  \n",
       "9     8.223                          [Birmensdorf ZH, Zentrum]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## calculate minimum/maximum latitude/longtitude given a fixed distance\n",
    "def compute_distance_inverse(lat, lng, distance):\n",
    "    radius = 6371\n",
    "\n",
    "    ## latitude boundaries\n",
    "    maxlat = lat + np.rad2deg(distance / radius)\n",
    "    minlat = lat - np.rad2deg(distance / radius)\n",
    "\n",
    "    ## longitude boundaries (longitude gets smaller when latitude increases)\n",
    "    maxlng = lng + np.rad2deg(distance / radius / np.cos(np.deg2rad(lat)))\n",
    "    minlng = lng - np.rad2deg(distance / radius / np.cos(np.deg2rad(lat)))\n",
    "    return maxlat, minlat, maxlng, minlng\n",
    "\n",
    "## add neighbor station for each station\n",
    "zurich_neigh_station = zurich_neigh_station.reset_index()\n",
    "zurich_neigh_station = zurich_neigh_station.drop(columns = [\"index\"])\n",
    "zurich_neigh_station.longtitude = zurich_neigh_station.longtitude.apply(lambda x: float(x))\n",
    "zurich_neigh_station.latitude = zurich_neigh_station.latitude.apply(lambda x: float(x))\n",
    "\n",
    "lng = zurich_neigh_station.longtitude.values\n",
    "lat = zurich_neigh_station.latitude.values\n",
    "maxlat, minlat, maxlng, minlng = compute_distance_inverse(lat, lng, distance = 0.2)\n",
    "\n",
    "neighbor = []\n",
    "\n",
    "for i in range (zurich_neigh_station.shape[0]):\n",
    "    loc = np.where(((maxlat[i] > lat) == True) & ((minlat[i] < lat) == True) & ((maxlng[i] > lng) == True) & ((minlng[i] < lng) == True))\n",
    "    neighbor.append(((zurich_neigh_station.name.values[loc[0]])))\n",
    "d = pd.Series(neighbor)\n",
    "zurich_neigh_station['neighbor'] = d\n",
    "zurich_neigh_station.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Build the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make use of the networkx package to build the graph. Firstly, we add all the edges in the multi-graph. Secondly, we add the walking as an additional transportation type. Then we reduce the multi-edge graph to single edge graph, which reduces the graph searching time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildGraph():\n",
    "    \n",
    "    ## Build the Multidigraph to record all the paths\n",
    "    Multi_G = nx.MultiDiGraph()\n",
    "    for index, item in df_day.iterrows():\n",
    "        train_number = item[\"train_number\"]\n",
    "        num_stop = len(item[\"station_name\"])\n",
    "        for i in range (num_stop - 1):\n",
    "            arrival = item[\"station_name\"][i + 1]\n",
    "            departure = item[\"station_name\"][i]\n",
    "            Multi_G.add_edge(departure, arrival, train_number = train_number)\n",
    "\n",
    "    ## Add the walking edge in multidigraph\n",
    "    cnt = 0\n",
    "    nodes = list(Multi_G.nodes)\n",
    "    for index, item in zurich_neigh_station.iterrows():\n",
    "        departure = item[\"name\"]\n",
    "        for i in range(len(item[\"neighbor\"])):\n",
    "            ## give walking edge an unique id\n",
    "            cnt += 1\n",
    "            if(item[\"neighbor\"].size != 0):\n",
    "                arrival = item[\"neighbor\"][i]\n",
    "                if((departure in nodes) & (arrival in nodes)):\n",
    "                    placeAdf = zurich_neigh_station[zurich_neigh_station['name']==arrival]\n",
    "                    placeBdf = zurich_neigh_station[zurich_neigh_station['name']==departure]\n",
    "                    distance = compute_distance(placeAdf.latitude.values[0], \n",
    "                                placeAdf.longtitude.values[0], \n",
    "                                placeBdf.latitude.values[0], \n",
    "                                placeBdf.longtitude.values[0])\n",
    "                    Multi_G.add_edge(departure, arrival, train_number = \"Walk_\" + str(cnt) + \",\" + str(distance))\n",
    "    \n",
    "    ## Reduce Multidigraph to digraph\n",
    "    G = nx.DiGraph()\n",
    "    nodes = list(Multi_G.nodes)\n",
    "    for i in range (len(nodes)):\n",
    "        for j in range(len(nodes)):    \n",
    "            stop_1 = nodes[i]\n",
    "            stop_2 = nodes[j]        \n",
    "            if (i != j):\n",
    "                edge_dict = Multi_G.get_edge_data(stop_1, stop_2)\n",
    "                path_list = set()      \n",
    "                ## transform multiedge into one edge with a list of labels\n",
    "                if(edge_dict != None):\n",
    "                    for k in edge_dict.keys():\n",
    "                        path_list.add(edge_dict[k]['train_number'])\n",
    "                    G.add_edge(stop_1, stop_2, train_number = path_list)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_path(G, start, destination, max_edges):\n",
    "    '''\n",
    "        It searches all possible paths on the given graph with the given starts,\n",
    "        destinations and max_edges.\n",
    "    '''\n",
    "    trips = []\n",
    "    for path in nx.all_simple_paths(G, source = start, target = destination, cutoff = max_edges):\n",
    "        vehicles = []\n",
    "        for i in range (len(path) - 1):\n",
    "            stop_1 = path[i]\n",
    "            stop_2 = path[i + 1]\n",
    "            edge_dict = G.get_edge_data(stop_1, stop_2)\n",
    "            vehicles.append(list(edge_dict['train_number']))\n",
    "        trips.append([path, vehicles])\n",
    "    return trips   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = BuildGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gpickle(G, \"./data/graph_200_0430.gpickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One route:\n",
      " ['Zürich Oerlikon', 'Glattbrugg', 'Glattbrugg, Bahnhof', 'Opfikon, Bahnhof']\n",
      "The corresponding bus/train number:\n",
      " [['18990', '19528', '19560', '19518', '19574', '18934', '18976', '18952', '19572', '18950', '18068', '18060', '19556', '19564', '19554', '18924', '18964', '19580', '19534', '18960', '18920', '18986', '18984', '18928', '19532', '18982', '18954', '19540', '19546', '18932', '18968', '19570', '19588', '19536', '19582', '19544', '19584', '19578', '19548', '18958', '18926', '18946', '19524', '19538', '18936', '18938', '19530', '18942', '19568', '18064', '19552', '19550', '19562', '18970', '18980', '19586', '18966', '19576', '19520', '18972', '18944', '19542', '18940', '19526', '19590', '19558', '18930', '19566', '19122', '18992', '18988', '18948', '18974', '18916', '18922', '18978', '19522', '18956', '18962'], ['Walk_162,0.049'], ['85:773:761', 'Walk_791,0.204']]\n"
     ]
    }
   ],
   "source": [
    "trip = find_path(G, start = 'Zürich Oerlikon', destination = 'Opfikon, Bahnhof', max_edges = 3)\n",
    "print('One route:\\n', trip[0][0])\n",
    "print('The corresponding bus/train number:\\n', trip[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Route filtering\n",
    "## 5.1 aggregate trips\n",
    "As shown above, each station corresponds to many trips (represented by bus/train number). However, we prefer to find direct trips and those trips having few interchanges. Therefore, we have to aggregate these trips. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_trips(trips_candidates: list, num_interchange: int = 10):\n",
    "    '''\n",
    "        It keeps all direct trips and those trips having few interchanges. \n",
    "        Firstly, we convert all trips into set, then we conduct intersection \n",
    "        on these sets to figure out all transfers.\n",
    "    '''\n",
    "    candidates_trips = []\n",
    "    for trip in trips_candidates:\n",
    "        \n",
    "        # load bus and station \n",
    "        bus_list = trip[1]\n",
    "        station_list = trip[0]\n",
    "        \n",
    "        # initialize set\n",
    "        new_set = {}\n",
    "        old_set = {}\n",
    "        aggre_trip = []\n",
    "        aggre_statation = [station_list[0]]\n",
    "        \n",
    "        cnt = 0\n",
    "        while cnt <= len(bus_list):\n",
    "            if len(new_set) == 0:\n",
    "            # new_set being empty meanings this is the first set or this station \n",
    "            # is a transfer.\n",
    "                if len(old_set) != 0:\n",
    "                # old_set not empty means this is a transfer\n",
    "                    cnt -= 1\n",
    "                    aggre_trip.append(list(old_set))\n",
    "                    aggre_statation.append(station_list[cnt])\n",
    "                    \n",
    "                    new_set = set(bus_list[cnt])\n",
    "                    old_set = {}\n",
    "                else:\n",
    "                    new_set = set(bus_list[cnt])\n",
    "            else:\n",
    "                # sets intersection to find a path\n",
    "                old_set = new_set\n",
    "                if cnt < len(bus_list):\n",
    "                    new_set = new_set.intersection(set(bus_list[cnt]))   \n",
    "            cnt += 1\n",
    " \n",
    "        # append possible trips (might be unresonable)\n",
    "        aggre_trip.append(list(new_set))\n",
    "        aggre_statation.append(station_list[-1])\n",
    "        \n",
    "        if len(aggre_trip) <= num_interchange:\n",
    "        # throw trips with more than num_interchange transfer\n",
    "            candidates_trips.append([aggre_statation, aggre_trip])\n",
    "    \n",
    "    return candidates_trips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 filter trips with time constraints\n",
    "Thought trips have been aggregated, as there is no time constraint such as arrival time and departure time, the 'aggreagate_trips' might contain some unreasonable trips. For exmaple, a bus departs at 14:30 while the user wants to departure at 12:30.\n",
    "\n",
    "Thus, a filter based on time constraints is implemented. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_trips(trips_list: list, bus_to_tripId: dict, time_table: dict, dist_map: pd.DataFrame, start_time: str):\n",
    "    '''\n",
    "        It filters out trips that are unresonable. In order to reduce the combination, \n",
    "        the filer is separated into two phases:\n",
    "            1. roughly filtering: filter trips by group to reduce the number of combination\n",
    "            2. second filtering : filter trips by path\n",
    "    '''\n",
    "    # First phase\n",
    "    trips_list = time_filter(trips_list, bus_to_tripId, time_table, dist_map, start_time )\n",
    "    \n",
    "    # Second phase\n",
    "    candidates_trips = []\n",
    "    for trip in trips_list:\n",
    "        new_paths = []\n",
    "        buses = trip[1]\n",
    "        stops = trip[0]\n",
    "        # throw invalid trips\n",
    "        if buses is None:\n",
    "            continue\n",
    "        \n",
    "        trip_combination = [ i for i in itertools.product(*buses)]\n",
    "        stops_list = [stops] * len(trip_combination)\n",
    "        for ind in range(len(trip_combination)):\n",
    "            new_paths.append( [ stops_list[ind], [ [bus] for bus in trip_combination[ind]] ])\n",
    "       \n",
    "        path_list = time_filter(new_paths, bus_to_tripId, time_table, dist_map, start_time, second_phase=True)\n",
    "        candidates_trips.append(path_list)\n",
    "        \n",
    "    return candidates_trips\n",
    "\n",
    "\n",
    "\n",
    "def time_filter(trips_list: list, bus_to_tripId: dict, time_table: dict, dist_map: pd.DataFrame, start_time: str, second_phase:bool=False):\n",
    "    '''\n",
    "        It uses time constraint to filter trips\n",
    "    '''\n",
    "    for ind_trips in range(len(trips_list)):\n",
    "        \n",
    "        stations, vehicle = trips_list[ind_trips][0], trips_list[ind_trips][1]\n",
    "        \n",
    "        old_trips = None\n",
    "        walk_arr_early = None\n",
    "        walk_arr_late  = None\n",
    "        \n",
    "        for ind in range(len(vehicle)):\n",
    "        # for the ind-th stop    \n",
    "            new_transfer = stations[ind]\n",
    "            new_buses = vehicle[ind]\n",
    "            \n",
    "            if old_trips is None:\n",
    "            # if this is the first stop then use the given start time \n",
    "                start_time_earliest = datetime.strptime(start_time, _FORMAT_TIME)\n",
    "                start_time_latest = start_time_earliest\n",
    "                \n",
    "            else:    \n",
    "            # else this is an intermediate stop then use the latest arrival time as the start time \n",
    "                bus_arr_time = [datetime.strptime(time_table[trip][new_transfer][0], _FORMAT_TIME) for trip in old_trips if 'Walk' not in trip]\n",
    "                    \n",
    "                if 'Walk' in old_trips:\n",
    "                    bus_arr_time += [walk_arr_early, walk_arr_late]\n",
    "                \n",
    "                arr_time = sorted(bus_arr_time)\n",
    "                start_time_earliest = arr_time[0]\n",
    "                start_time_latest = arr_time[-1]\n",
    "            \n",
    "            next_transfer = stations[ind+1]\n",
    "            if sum(['Walk' in choice for choice in new_buses]):\n",
    "            # if new trips contain walk\n",
    "                dist = dist_map[ (dist_map['placeA'] == new_transfer) & (dist_map['placeB'] == next_transfer)].distance.values*1000\n",
    "                walk_arr_early= timedelta(seconds = dist[0]/_WALKING_VELOCITY) + start_time_earliest\n",
    "                walk_arr_late = timedelta(seconds = dist[0]/_WALKING_VELOCITY) + start_time_latest\n",
    "                \n",
    "            filtered_tripId = time_constraint(new_transfer, new_buses, next_transfer, bus_to_tripId, time_table, \n",
    "                                              start_time_earliest, start_time_latest, enable_second_phase=second_phase)\n",
    "            \n",
    "            if len(filtered_tripId) == 0:\n",
    "            # if one of the intermediate trips is invalid, throw all current trips\n",
    "                trips_list[ind_trips][1] = None\n",
    "                break \n",
    "            \n",
    "            old_trips = filtered_tripId\n",
    "            trips_list[ind_trips][1][ind] = filtered_tripId\n",
    "            \n",
    "    return trips_list\n",
    "\n",
    "\n",
    "def time_constraint(new_transfer : str, new_buses: list, next_transfer: str, bus_to_tripId: dict, \n",
    "                    time_table: dict, start_time_early: str, start_time_late: str, enable_second_phase: bool):\n",
    "    '''\n",
    "        It uses two simple time constraints to filter unresonable trips:\n",
    "            1. departure time must be later than arrival time.\n",
    "            2. departure time must be earier than arrival time + _LARGEST_DELAY.\n",
    "    '''\n",
    "    candidates = []\n",
    "    for bus in new_buses:\n",
    "        \n",
    "        if 'Walk' in bus:\n",
    "            trip_list = ['Walk']\n",
    "        elif enable_second_phase:\n",
    "            trip_list = new_buses               # for second phase filtering\n",
    "        else:\n",
    "            trip_list = bus_to_tripId[bus]      # if is not walk, load tripId\n",
    "             \n",
    "        for trip in trip_list:            \n",
    "            if trip == 'Walk':\n",
    "                candidates.append(trip)\n",
    "            else:\n",
    "                try:\n",
    "                    # if the trip does not stop at the station, we throw the trip.\n",
    "                    # This is possible when some trains share the same train_number while \n",
    "                    # they have different trips and one the target_arr trip pass the station.\n",
    "                    dep_time = datetime.strptime(time_table[trip][new_transfer][1], _FORMAT_TIME)\n",
    "                    if time_table[trip][next_transfer][0] == 'nan:nan':\n",
    "                        continue\n",
    "                    elif datetime.strptime(time_table[trip][next_transfer][0], _FORMAT_TIME) < dep_time:\n",
    "                        continue\n",
    "                except:\n",
    "                    continue\n",
    "                    \n",
    "                if dep_time is None:\n",
    "                    # if the time is invalid (NaN), we throw this trip\n",
    "                    continue\n",
    "                else:\n",
    "                    # compute time difference\n",
    "                    time_diff_early = dep_time - start_time_early\n",
    "                    time_diff_late  = dep_time - start_time_late\n",
    "                    minutes_late = int(time_diff_late.total_seconds()/60)\n",
    "                   \n",
    "                    if minutes_late >= _LARGEST_DELAY or int(time_diff_early.total_seconds()) <= _RELAXATION_FACTOR:\n",
    "                    # throw trips being later than _LARGEST_DELAY and earler than the earliest trip\n",
    "                        continue\n",
    "                    else:\n",
    "                        candidates.append(trip)\n",
    "            \n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data according to the given date, as trips are \n",
    "# different for weekday, weekend and pubilc holiday.\n",
    "\n",
    "def load_data(date: datetime):\n",
    "    \n",
    "    weekday = date.weekday()\n",
    "    \n",
    "    if  weekday <= 4:   # weekday data\n",
    "        path_schedual = './data/schedule_430.csv'  \n",
    "        path_graph    = './data/graph_200_0430.gpickle'  \n",
    "        path_lineID   = './data/lineid_trip180430.pickle'   \n",
    "        path_stdtime  = './data/timetable180430.pickle'   \n",
    "        \n",
    "    elif weekday == 5:  # weekend data\n",
    "        path_schedual = './data/schedule_428.csv'        \n",
    "        path_graph    = './data/graph_200_0428.gpickle'\n",
    "        path_lineID   = './data/lineid_trip180428.pickle'\n",
    "        path_stdtime  = './data/timetable180428.pickle'\n",
    "        \n",
    "    else:               # public holiday data\n",
    "        path_schedual = './data/schedule_429.csv'        \n",
    "        path_graph    = './data/graph_200_0429.gpickle'    \n",
    "        path_lineID   = './data/lineid_trip180429.pickle'       \n",
    "        path_stdtime  = './data/timetable180429.pickle'    \n",
    "        \n",
    "    with open(path_lineID,'rb') as file:       # bus number -> tripID\n",
    "        line_id = pickle.load(file)                             \n",
    "    \n",
    "    with open(path_stdtime,'rb') as file:      # tripID -> time\n",
    "        tripID_2_time = pickle.load(file)\n",
    "        \n",
    "    time_table = pd.read_csv(path_schedual)                             # table to get the absolute time of a given (tripsId, station_name) pair\n",
    "    graph = nx.read_gpickle(path_graph)                                 # graph\n",
    "    dist_map = pd.read_csv('./data/distMap.csv')                        # distance map betew\n",
    "    trip_table = pd.read_csv('./data/group_dense_time_table.csv')       # tripID -> all available time difference\n",
    "    \n",
    "    return time_table, graph, dist_map, trip_table, tripID_2_time, line_id, weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set some data for demostration \n",
    "departure_month = 'Apr'\n",
    "departure_day   = 30\n",
    "departure_hour  = 12\n",
    "departure_minute= 30\n",
    "\n",
    "arrival_month = 'Apr'\n",
    "arrival_day   = 30\n",
    "arrival_hour  = 13\n",
    "arrival_minute= 30\n",
    "\n",
    "# convert format\n",
    "dep_date = datetime.strptime( departure_month+ ' {:02d} {:02d}'.format(departure_day, _DEFAULT_YEAR_), '%b %d %Y')\n",
    "dep_time = '{:02d}:{:02d}'.format(departure_hour, departure_minute)\n",
    "\n",
    "arr_date = datetime.strptime( arrival_month + ' {:02d} {:02d}'.format(arrival_day, _DEFAULT_YEAR_)   , '%b %d %Y')\n",
    "arr_time = '{:02d}:{:02d}'.format(arrival_hour, arrival_minute)\n",
    "\n",
    "# load necessary tables\n",
    "date = datetime.strptime( departure_month+ ' {:02d} {:02d}'.format(departure_day, _DEFAULT_YEAR_), '%b %d %Y')\n",
    "time_table, graph, dist_map, trip_table, tripID_2_time, line_id, weekday = load_data(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregating trips\n",
    "aggregate_trip = aggregate_trips(trips_candidates=trip, num_interchange=3)\n",
    "\n",
    "# roughly filtering trips\n",
    "filtered_trips = filter_trips(aggregate_trip, line_id, tripID_2_time, dist_map, dep_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Route 0: ['Zürich Oerlikon', 'Glattbrugg', 'Glattbrugg, Bahnhof', 'Opfikon, Bahnhof']\n",
      "The corresponding bus/train number: [['85:11:19544:001'], ['Walk'], ['Walk']]\n",
      "\n",
      "\n",
      "Route 1: ['Zürich Oerlikon', 'Glattbrugg', 'Glattbrugg, Post', 'Opfikon, Bahnhof']\n",
      "The corresponding bus/train number: [['85:11:19544:001'], ['Walk'], ['Walk']]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ind, trip in enumerate(filtered_trips):\n",
    "    print('Route {:d}: {:s}'.format(ind, str(trip[0][0])))\n",
    "    print('The corresponding bus/train number:', trip[0][1])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
